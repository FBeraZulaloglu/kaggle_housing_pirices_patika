# kaggle_housing_pirices_patika
This project is to exerice my basic data science skills that I have learned with patika. clean_train_random_forest_xgb notebook cleans the housing prices data in Kaggle also train that data with RandomForest and XGBoost models. By cleaning the data I have categorized data and to clean none values I have replicated with the mean values. After these steps have finished I have trained the RandomForestRegressor model with different parameters. As an last model I tried to use XGBoost model and decided to use that model to predict test data.

STEPS:
1. Preprocess (categorize and clean nan values with mean values)
2. Train RandomForestRegressor
3. HyperParameter Tuning
4. Train XGBoost model
5. Predict
6. Upload the submission to the Kaggle platform

- data: https://www.kaggle.com/competitions/home-data-for-ml-course/data
- patika: www.patika.dev
- random forest = https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html
